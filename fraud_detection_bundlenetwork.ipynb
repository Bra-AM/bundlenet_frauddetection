{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV1hcvYHSSNp",
        "outputId": "5531c508-1d88-4c55-e905-08106ae0730e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FrEIA\n",
            "  Downloading FrEIA-0.2.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from FrEIA) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from FrEIA) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from FrEIA) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->FrEIA)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->FrEIA) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->FrEIA) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->FrEIA) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: FrEIA\n",
            "  Building wheel for FrEIA (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FrEIA: filename=FrEIA-0.2-py3-none-any.whl size=42762 sha256=26d808a9623d2cac6bfdf651aa524bf6482e61c05e22e8a2d7cb1964b8237dbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/9a/71/9519e52124ed311defc7d6d264ce91af24789b7fcfdea00ef4\n",
            "Successfully built FrEIA\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, FrEIA\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed FrEIA-0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install FrEIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VEpDQr3SSwf",
        "outputId": "dcb078fb-70ac-49fd-9a06-e6b3fa37aaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Credit Card Fraud Detection dataset found. Loading data...\n",
            "Data loaded successfully. Shape: (284807, 31)\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to data directory\n",
        "data_dir = '/content/drive/My Drive/bundlenet/'\n",
        "\n",
        "# Checking if the file exists\n",
        "import os\n",
        "file_path = os.path.join(data_dir, 'creditcard.csv')\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"The 'creditcard.csv' file is not found in the directory {data_dir}. Please make sure the file is in the correct location in your Google Drive.\")\n",
        "\n",
        "print(\"Credit Card Fraud Detection dataset found. Loading data...\")\n",
        "\n",
        "# Loading data\n",
        "import pandas as pd\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Data loaded successfully. Shape:\", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1czfNpdVib0",
        "outputId": "782f9e67-3c74-4d7b-9350-74efd99603d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available: True\n",
            "GPU Name: Tesla T4\n",
            "Number of GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CdDVxubT3lN"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "\n",
        "# SMOTE imports\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# FrEIA imports\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7b4tIQjSTJK",
        "outputId": "79e2a60b-ef6d-4115-878d-e775be4d1656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available: True\n",
            "GPU Name: Tesla T4\n",
            "Number of GPUs: 1\n",
            "Using device: cuda\n",
            "Preprocessing data...\n",
            "Applying SMOTE for class balance...\n",
            "Data preprocessing completed.\n",
            "Initializing model...\n",
            "Starting training...\n",
            "Epoch [10/100], Average Loss: 0.0000\n",
            "Epoch [20/100], Average Loss: 0.0000\n",
            "Epoch [30/100], Average Loss: 0.0000\n",
            "Epoch [40/100], Average Loss: 0.0000\n",
            "Epoch [50/100], Average Loss: 0.0000\n",
            "Epoch [60/100], Average Loss: 0.0000\n",
            "Epoch [70/100], Average Loss: 0.0000\n",
            "Epoch [80/100], Average Loss: 0.0000\n",
            "Epoch [90/100], Average Loss: 0.0000\n",
            "Epoch [100/100], Average Loss: 0.0000\n",
            "Evaluating model...\n",
            "AUC-ROC: 1.0000\n",
            "Average Precision: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Exploring fibers...\n",
            "\n",
            "Low-risk transaction samples (first 5 features):\n",
            "tensor([[  0.6097,   3.3165,  12.1029, 109.0091,  99.1455],\n",
            "        [  1.3128, -21.7661,  42.8486, 273.4642, 279.2777],\n",
            "        [  0.7159,  -2.7537,  14.8695,  62.1992,  93.6846],\n",
            "        [  0.4581,   2.7457,  10.2465,  53.1518,  79.4078],\n",
            "        [  1.0581,  -5.2629,  30.2156, 109.7092, 186.1660]])\n",
            "\n",
            "High-risk transaction samples (first 5 features):\n",
            "tensor([[  1.6908,  70.1618,  35.0872, 191.8798, -52.8616],\n",
            "        [  0.8321,  16.0983,  10.6598,  45.7725,  -7.8184],\n",
            "        [  1.4109,  23.1335,  16.0461, 138.2387, -37.5583],\n",
            "        [  0.4882,  31.5969,  16.1842,  53.3778,  13.6038],\n",
            "        [  0.9608,  25.3504,  21.2609, 145.7025, -35.8340]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import FrEIA.framework as Ff\n",
        "import FrEIA.modules as Fm\n",
        "\n",
        "class BundleNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_nbhds=25, width=512, num_inv_blocks=5, nn_depth=5):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_nbhds = num_nbhds\n",
        "\n",
        "        def subnet_fc(c_in, c_out):\n",
        "            return nn.Sequential(\n",
        "                nn.Linear(c_in, width),\n",
        "                nn.ReLU(),\n",
        "                *[nn.Linear(width, width), nn.ReLU()] * nn_depth,\n",
        "                nn.Linear(width, c_out)\n",
        "            )\n",
        "\n",
        "        # Building the invertible network\n",
        "        nodes = [Ff.InputNode(input_dim, name='input')]\n",
        "        cond_node = Ff.ConditionNode(1, name='fraud_prob')\n",
        "\n",
        "        # Adding coupling blocks\n",
        "        for k in range(num_inv_blocks):\n",
        "            nodes.append(Ff.Node(nodes[-1],\n",
        "                               Fm.GLOWCouplingBlock,\n",
        "                               {'subnet_constructor': subnet_fc, 'clamp': 2.0},\n",
        "                               conditions=cond_node,\n",
        "                               name=f'coupling_{k}'))\n",
        "            nodes.append(Ff.Node(nodes[-1],\n",
        "                               Fm.PermuteRandom,\n",
        "                               {'seed': k},\n",
        "                               name=f'permute_{k}'))\n",
        "\n",
        "        nodes.append(Ff.OutputNode(nodes[-1], name='output'))\n",
        "        self.model = Ff.GraphINN(nodes + [cond_node])\n",
        "\n",
        "    def forward(self, x, c):\n",
        "        x = x.reshape(-1, self.input_dim)\n",
        "        c = c.reshape(-1, 1)\n",
        "        return self.model(x, c=[c])\n",
        "\n",
        "    def reverse(self, z, c):\n",
        "        z = z.reshape(-1, self.input_dim)\n",
        "        c = c.reshape(-1, 1)\n",
        "        return self.model(z, c=[c], rev=True)\n",
        "\n",
        "    def sample_from_fiber(self, fraud_prob, n=1):\n",
        "        z = torch.randn(n, self.input_dim)\n",
        "        c = fraud_prob.repeat(n, 1)\n",
        "        return self.reverse(z, c)\n",
        "\n",
        "# Checking GPU\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "\n",
        "# Device setting\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data preprocessing\n",
        "print(\"Preprocessing data...\")\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Applying SMOTE for class balance...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Move data to GPU immediately after creation\n",
        "X_train_tensor = torch.FloatTensor(X_train_resampled).to(device)\n",
        "y_train_tensor = torch.FloatTensor(y_train_resampled.values).unsqueeze(1).to(device)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
        "y_test_tensor = torch.FloatTensor(y_test.values).unsqueeze(1).to(device)\n",
        "\n",
        "print(\"Data preprocessing completed.\")\n",
        "\n",
        "# Model initialization\n",
        "print(\"Initializing model...\")\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "model = BundleNet(input_dim).to(device)\n",
        "\n",
        "# Loss functions and optimizer (move to GPU)\n",
        "mse_loss = nn.MSELoss().to(device)\n",
        "bce_loss = nn.BCEWithLogitsLoss().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Create DataLoader\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Modified train_model function\n",
        "def train_model(model, train_loader, num_epochs=100):\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            encoded, _ = model(batch_x, batch_y)\n",
        "\n",
        "            # Reconstruction\n",
        "            reconstructed, _ = model.reverse(encoded, batch_y)\n",
        "\n",
        "            # Losses\n",
        "            recon_loss = mse_loss(reconstructed, batch_x)\n",
        "            fraud_loss = bce_loss(encoded[:, 0:1], batch_y)\n",
        "\n",
        "            loss = recon_loss + fraud_loss\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "                  f'Average Loss: {epoch_loss/len(train_loader):.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, train_loader, num_epochs=100)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating model...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "    encoded_test, _ = model(X_test_tensor, y_test_tensor)\n",
        "    fraud_probs = torch.sigmoid(encoded_test[:, 0]).cpu()\n",
        "\n",
        "y_test_np = y_test.values\n",
        "auc_roc = roc_auc_score(y_test_np, fraud_probs)\n",
        "avg_precision = average_precision_score(y_test_np, fraud_probs)\n",
        "f1 = f1_score(y_test_np, (fraud_probs > 0.5))\n",
        "\n",
        "print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "print(f'Average Precision: {avg_precision:.4f}')\n",
        "print(f'F1-score: {f1:.4f}')\n",
        "\n",
        "# Fiber exploration\n",
        "print(\"\\nExploring fibers...\")\n",
        "with torch.no_grad():\n",
        "    test_device = torch.device('cpu')\n",
        "    model = model.to(test_device)\n",
        "\n",
        "    low_risk = torch.tensor([[0.1]], device=test_device)\n",
        "    high_risk = torch.tensor([[0.9]], device=test_device)\n",
        "\n",
        "    low_risk_sample, _ = model.sample_from_fiber(low_risk, n=5)\n",
        "    high_risk_sample, _ = model.sample_from_fiber(high_risk, n=5)\n",
        "\n",
        "print(\"\\nLow-risk transaction samples (first 5 features):\")\n",
        "print(low_risk_sample[:, :5])\n",
        "print(\"\\nHigh-risk transaction samples (first 5 features):\")\n",
        "print(high_risk_sample[:, :5])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}